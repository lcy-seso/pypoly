**Variable Type**

- Tensor (scalar represented as tensor?)
  - data type
  - shape
  - layout
- List
  - length
  - item type (label reference? *repeat*)
  - storage of items
  - List is initialized by definition. *map*, *scan* and *for* are used to build List(constructor functions). Note that the representation is not strongly related to the implemention, referring to the example code in Grid RNN
  - List structure follows functional programming model, immutable and no modification interface( like append) is provided
- Tensor Array (inherit from *List*)
  - item type specialization: tensors, tensor arrays
  - tensor info
  - depth
  - layout
  - label the static and dynamic dimensions?
  - dynamic dimension reference?
- Tuple (inherit from *List*)
  - item type specialization: object references
- Object Reference
  - pointer to source object, limited types of source object: tensor, tensor arrays

**Op Type (system interfaces)**

- basic arithmetic (scalar level)
  - unary
    - neg
  - binary
    - add, sub, mul, div
    - eq, ne, le, ge, lt, gt
    - and, xor, or, not
    - max, min
- tensor (array) operation (to be discussed)
  - read
  - write
  - generation / initialization
    - repeat
- computation: *a* and *b* below are all tensors, iterable object refers to data structures inherited from *List*
  - map
    - iterable object: List[*a*]
    - lambda function: *a* -> *b*
    - return type: List[*b*]
  - scan (fold, reduce)
    - initial variable: *a*
    - iterable object: List[*b*]
    - lambda function: (*a*, *b*) -> *a*
    - return type: List[*a*]
  - for (we argue that *for* is constrained in the frontend and fully functioning in the backend)
    - iteration domain: List[iteration variable]
      - iteration variable: Tuple<name,lower_bound,upper_bound,increment>
      - name: expr, int
      - lower_bound: expr, int
      - upper_bound: expr, int
      - increment: expr, int
    - lambda function: (List[int]) -> a
- data movement
  - gather
    - iterable variable: List[*a*]
    - index: List[tuple<*int*>]
    - dimension: int
    - return type: *b*
  - scatter
    - iterable variable: List[*a*]
    - input tensor: *b*
    - index: List[tuple<*int*>]
    - dimension: int
    - no return type, in place assignment / modification to the iterable variable
- data access
  - index (currently, we constrain that the arguement of index is a single induction variable, not an expression composed of algebraic combination of variables)
    - access position: int

Expr Access Type

- may read
- may write
- must write

Expr

- type ? (check the array part in PET)
- args: List[Expr]

Expr Type

- access (variable name is covered in this category)
  - access type
- call
  - func-name (optional for lambda function): string
- op
  - op type
- int (initial value, increment)

Tree

- computation
  - inputs: List[Expr]
  - output: Expr
  - block: Tree
- expr (differences against decl-init), call functions with no return statement
  - expr: Expr
- block
  - children: List[Tree]
- decl-init
  - var: Expr
  - init: Expr
- if-else
  - cond: Expr
  - then-body: Tree
  - else-body: Tree
- for
  - iv: Expr
  - init: Expr
  - cond: Expr
  - inc: Expr
  - body: Tree

Important functionalities of IR(Tree)

- Shape propagation: static and dynamic
- Function signature generation
- Meta info propagation: tell whether inputs of a function can be batched
- Fuse / merge code (tree, computation)

Notes

1. no assignment in op type, assignment in a statement is stored as a 'decl-init' tree node
2. arithmetic ops are only operated on scalar values
3. computations on tensor in a statement are represented by function calls, like matrix multiply and broadcast add
4. like PET, a variable is represented by an access expression
5. different from PET, no 'int' or 'double' types, all variables are either Tensor or Tensor Array type
6. Tensor and Tensor Array here are all logic objects. Physical memory space is not considered and left for runtime memory management. Layout plan is generated by the compiler.
7. nested function calls will be split into multiple statements following SSA rules
8. tensors and tensor arrays are generated by *functions* or *nested loops*, for tensors, static dimensions are inferred directly from the static loop bound, for tensor arrays, dynamic (parametric) dimensions are inherited or inferred from the dynamic loop bound